{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "845673f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key successfully loaded.\n",
      "‚úÖ Vector Database Connected.\n",
      "‚úÖ Judge LLM Initialized.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\" \n",
    "\n",
    "if os.environ[\"GROQ_API_KEY\"].startswith(\"gsk_\"):\n",
    "    print(\"‚úÖ API Key successfully loaded.\")\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Please paste your valid Groq API Key in the code above!\")\n",
    "\n",
    "\n",
    "try:\n",
    "    embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    if os.path.exists(\"./chroma_db\"):\n",
    "        db = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding)\n",
    "        retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "        print(\"‚úÖ Vector Database Connected.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Warning: 'chroma_db' folder not found. RAG functionality will fail.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading Database: {e}\")\n",
    "\n",
    "try:\n",
    "    llm_judge = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)\n",
    "    print(\"‚úÖ Judge LLM Initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LLM Connection Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1071dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [\n",
    "    {\n",
    "        \"question\": \"What are the primary risks mentioned for this company?\",\n",
    "        \"ground_truth\": \"Volatility in oil prices and regulatory changes.\" # <--- CHANGE THIS to match your PDF\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the outlook on future growth?\",\n",
    "        \"ground_truth\": \"Focus on renewable energy and 5G expansion.\" # <--- CHANGE THIS to match your PDF\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adc4df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag(question, ground_truth):\n",
    "    # 1. Run Retrieval\n",
    "    docs = retriever.invoke(question)\n",
    "    retrieved_context = \"\\n\".join([d.page_content for d in docs])\n",
    "    \n",
    "    # 2. Ask the Judge\n",
    "    prompt = f\"\"\"\n",
    "    You are a strict teacher grading an AI's homework.\n",
    "    \n",
    "    User Question: {question}\n",
    "    Expected Answer (Ground Truth): {ground_truth}\n",
    "    \n",
    "    Actual Retrieved Context by AI:\n",
    "    {retrieved_context}\n",
    "    \n",
    "    ---\n",
    "    TASK:\n",
    "    Does the \"Actual Retrieved Context\" contain the information needed to answer the question according to the \"Ground Truth\"?\n",
    "    \n",
    "    Reply with ONLY one word: 'PASS' or 'FAIL'.\n",
    "    Then provide a 1-sentence explanation.\n",
    "    \"\"\"\n",
    "    \n",
    "    score = llm_judge.invoke(prompt).content\n",
    "    return score, retrieved_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81bcfd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ STARTING RAG EVALUATION...\n",
      "\n",
      "‚ùì Testing: What are the primary risks mentioned for this company?\n",
      "üìù Result: FAIL. The \"Actual Retrieved Context\" does not mention volatility in oil prices and regulatory changes, which are the primary risks mentioned in the \"Ground Truth\".\n",
      "------------------------------\n",
      "‚ùì Testing: What is the outlook on future growth?\n",
      "üìù Result: FAIL. The \"Actual Retrieved Context\" does not contain the specific information about focusing on renewable energy and 5G expansion as required by the \"Ground Truth\" to answer the question about the outlook on future growth.\n",
      "------------------------------\n",
      "\n",
      "üèÜ FINAL SYSTEM GRADE: 0.0% Accuracy\n",
      "‚ö†Ô∏è Recommendation: Improve chunk size or PDF quality.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "print(\"üß™ STARTING RAG EVALUATION...\\n\")\n",
    "\n",
    "for item in test_set:\n",
    "    print(f\"‚ùì Testing: {item['question']}\")\n",
    "    score, context = evaluate_rag(item['question'], item['ground_truth'])\n",
    "    print(f\"üìù Result: {score}\")\n",
    "    print(\"-\" * 30)\n",
    "    results.append(score)\n",
    "\n",
    "# Calculate Accuracy\n",
    "pass_count = sum(1 for r in results if \"PASS\" in r)\n",
    "accuracy = (pass_count / len(test_set)) * 100\n",
    "\n",
    "print(f\"\\nüèÜ FINAL SYSTEM GRADE: {accuracy}% Accuracy\")\n",
    "if accuracy < 50:\n",
    "    print(\"‚ö†Ô∏è Recommendation: Improve chunk size or PDF quality.\")\n",
    "else:\n",
    "    print(\"‚úÖ System Ready for Production.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAT496",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
